## Learning parameters

# Params for optimizer
learning_rate: 1e-3
weight_decay: 1e-5

sync_rate: 100  # Number of turns to copy weight from `eval_net` to target network -> Q_iteration
replay_size: 10
lr_reduce_rate: 0.999  # Learning rate reduction rate
eps_last_frame: 200
eps_start: 0.1
eps_end: 0.01
n_episodes: 200
episode_length: 200
gamma: 0.9  # Reward reduction rate

load_checkpoint: false
checkpoint_dir: ${root}/checkpoints
checkpoint_path: 
memory_filename: 2d_memory.npy
